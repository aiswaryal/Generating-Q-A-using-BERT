{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final mcq.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1uwZnwHDATo0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593108026134,"user_tz":-330,"elapsed":11767,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"9a11ac8f-b617-4d92-ea66-82e036ccbb5a"},"source":["!sudo python -m nltk.downloader all\n","!pip install rake-nltk\n","!pip install gensim\n","!pip install word2vec\n","!pip install pytextrank\n","!pip install git+https://github.com/boudinfl/pke.git\n","!pip install -U pywsd\n","!pip install spacy\n","!pip install -U nltk\n","!pip install flashtext"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Package abc is already up-to-date!\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Package alpino is already up-to-date!\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Package brown is already up-to-date!\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Package brown_tei is already up-to-date!\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Package cess_cat is already up-to-date!\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Package cess_esp is already up-to-date!\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Package chat80 is already up-to-date!\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package city_database is already up-to-date!\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Package cmudict is already up-to-date!\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package comparative_sentences is already up-to-\n","[nltk_data]    |       date!\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    |   Package comtrans is already up-to-date!\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Package conll2000 is already up-to-date!\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Package conll2002 is already up-to-date!\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    |   Package conll2007 is already up-to-date!\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Package crubadan is already up-to-date!\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package dependency_treebank is already up-to-date!\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Package dolch is already up-to-date!\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package europarl_raw is already up-to-date!\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Package floresta is already up-to-date!\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package framenet_v15 is already up-to-date!\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package framenet_v17 is already up-to-date!\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Package gazetteers is already up-to-date!\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Package genesis is already up-to-date!\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Package gutenberg is already up-to-date!\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Package ieer is already up-to-date!\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Package inaugural is already up-to-date!\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Package indian is already up-to-date!\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    |   Package jeita is already up-to-date!\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Package kimmo is already up-to-date!\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    |   Package knbc is already up-to-date!\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Package mac_morpho is already up-to-date!\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    |   Package machado is already up-to-date!\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    |   Package masc_tagged is already up-to-date!\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package moses_sample is already up-to-date!\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package movie_reviews is already up-to-date!\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Package names is already up-to-date!\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Package nps_chat is already up-to-date!\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    |   Package omw is already up-to-date!\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Package paradigms is already up-to-date!\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Package pil is already up-to-date!\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Package pl196x is already up-to-date!\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Package ppattach is already up-to-date!\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package problem_reports is already up-to-date!\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    |   Package propbank is already up-to-date!\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Package ptb is already up-to-date!\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Package pros_cons is already up-to-date!\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Package qc is already up-to-date!\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    |   Package reuters is already up-to-date!\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Package rte is already up-to-date!\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    |   Package semcor is already up-to-date!\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Package senseval is already up-to-date!\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sentiwordnet is already up-to-date!\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sentence_polarity is already up-to-date!\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Package shakespeare is already up-to-date!\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sinica_treebank is already up-to-date!\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Package smultron is already up-to-date!\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Package state_union is already up-to-date!\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Package stopwords is already up-to-date!\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package subjectivity is already up-to-date!\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Package swadesh is already up-to-date!\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Package switchboard is already up-to-date!\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Package timit is already up-to-date!\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Package toolbox is already up-to-date!\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Package treebank is already up-to-date!\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package twitter_samples is already up-to-date!\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Package udhr is already up-to-date!\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Package udhr2 is already up-to-date!\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package unicode_samples is already up-to-date!\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n","[nltk_data]    |       date!\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Package verbnet is already up-to-date!\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Package verbnet3 is already up-to-date!\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Package webtext is already up-to-date!\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Package wordnet is already up-to-date!\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Package wordnet_ic is already up-to-date!\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Package words is already up-to-date!\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Package ycoe is already up-to-date!\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Package rslp is already up-to-date!\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n","[nltk_data]    |       to-date!\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package universal_tagset is already up-to-date!\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Package punkt is already up-to-date!\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package book_grammars is already up-to-date!\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sample_grammars is already up-to-date!\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package spanish_grammars is already up-to-date!\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package basque_grammars is already up-to-date!\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package large_grammars is already up-to-date!\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Package tagsets is already up-to-date!\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package snowball_data is already up-to-date!\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package word2vec_sample is already up-to-date!\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Package mte_teip5 is already up-to-date!\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n","[nltk_data]    |       to-date!\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n","[nltk_data]    |       up-to-date!\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package perluniprops is already up-to-date!\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package vader_lexicon is already up-to-date!\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Package porter_test is already up-to-date!\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Package wmt15_eval is already up-to-date!\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n","Requirement already satisfied: rake-nltk in /usr/local/lib/python3.6/dist-packages (1.0.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rake-nltk) (3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk->rake-nltk) (4.46.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk->rake-nltk) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk->rake-nltk) (0.15.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk->rake-nltk) (2020.6.8)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.5.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.0)\n","Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.24.0)\n","Requirement already satisfied: botocore<1.18.0,>=1.17.5 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.5)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.25.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.5->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.5->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n","Requirement already satisfied: word2vec in /usr/local/lib/python3.6/dist-packages (0.11.1)\n","Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from word2vec) (1.19.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from word2vec) (0.15.1)\n","Requirement already satisfied: pytextrank in /usr/local/lib/python3.6/dist-packages (2.0.2)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pytextrank) (2.3.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pytextrank) (2.4)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from pytextrank) (0.10.1)\n","Requirement already satisfied: coverage in /usr/local/lib/python3.6/dist-packages (from pytextrank) (3.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (47.3.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.0.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (2.24.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (0.7.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.19.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (4.46.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.0.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (2.0.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (3.0.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.1.3)\n","Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (7.4.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pytextrank) (4.4.2)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pytextrank) (1.6.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (1.25.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2020.6.20)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pytextrank) (3.1.0)\n","Collecting git+https://github.com/boudinfl/pke.git\n","  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-0i2_afrx\n","  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-0i2_afrx\n","Requirement already satisfied (use --upgrade to upgrade): pke==1.8.1 from git+https://github.com/boudinfl/pke.git in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (3.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (2.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.19.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.5.0)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (2.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.15.0)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.0)\n","Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.1.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.16.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.15.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk->pke==1.8.1) (2020.6.8)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk->pke==1.8.1) (4.46.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk->pke==1.8.1) (7.1.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pke==1.8.1) (4.4.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (2.24.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (0.7.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (3.0.2)\n","Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (7.4.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.2)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (47.3.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (2.0.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (0.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->pke==1.8.1) (0.23.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (1.25.9)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (1.6.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->pke==1.8.1) (2.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.1.0)\n","Building wheels for collected packages: pke\n","  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pke: filename=pke-1.8.1-cp36-none-any.whl size=8759715 sha256=c94d2c4ddab809544e47a27a8c46dbef180cea52eaef2d45e75152ca699d0e88\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-gputd2xr/wheels/8d/24/54/6582e854e9e32dd6c632af6762b3a5d2f6b181c2992e165462\n","Successfully built pke\n","Requirement already up-to-date: pywsd in /usr/local/lib/python3.6/dist-packages (1.2.4)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.15.0)\n","Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.0.5)\n","Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from pywsd) (3.5)\n","Requirement already satisfied, skipping upgrade: wn in /usr/local/lib/python3.6/dist-packages (from pywsd) (0.0.23)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.19.0)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pywsd) (2018.9)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->pywsd) (2.8.1)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk->pywsd) (2020.6.8)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk->pywsd) (0.15.1)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk->pywsd) (7.1.2)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk->pywsd) (4.46.1)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.3.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.24.0)\n","Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.19.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.46.1)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n","Requirement already up-to-date: nltk in /usr/local/lib/python3.6/dist-packages (3.5)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2020.6.8)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.46.1)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.15.1)\n","Requirement already satisfied: flashtext in /usr/local/lib/python3.6/dist-packages (2.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zik-VrXbYL_v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593108085640,"user_tz":-330,"elapsed":59522,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"25f86b92-89b7-4462-aa5b-790139ea3788"},"source":["!python3 -m spacy download en_core_web_sm\n","!pip install bert-extractive-summarizer --upgrade --force-reinstall"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.3.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.0/en_core_web_sm-2.3.0.tar.gz#egg=en_core_web_sm==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.3.0) (2.3.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.19.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (4.46.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.1.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.24.0)\n","Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (7.4.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (47.3.1)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (0.4.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (0.7.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.0.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.6.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.25.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2020.6.20)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.1.0)\n","\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","Processing /root/.cache/pip/wheels/13/bc/30/654eb9e657177a56cba927c5a20b6cd01fb229b1ed2bf9b371/bert_extractive_summarizer-0.4.2-cp36-none-any.whl\n","Collecting transformers\n","  Using cached https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl\n","Collecting scikit-learn\n","  Using cached https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting spacy\n","  Using cached https://files.pythonhosted.org/packages/31/c7/e66e2af1cfa418c3a3917c116c4e00ccffa546f18f59e6acd7953d833c5c/spacy-2.3.0-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting regex!=2019.12.17\n","  Using cached https://files.pythonhosted.org/packages/1a/a1/6d8fdf4a20ffbbf2bd6003dff47a0628b9e6a4b840c421b0dec27da9376e/regex-2020.6.8-cp36-cp36m-manylinux2010_x86_64.whl\n","Collecting filelock\n","  Using cached https://files.pythonhosted.org/packages/93/83/71a2ee6158bb9f39a90c0dea1637f81d5eef866e188e1971a1b1ab01a35a/filelock-3.0.12-py3-none-any.whl\n","Collecting numpy\n","  Using cached https://files.pythonhosted.org/packages/93/0b/71ae818646c1a80fbe6776d41f480649523ed31243f1f34d9d7e41d70195/numpy-1.19.0-cp36-cp36m-manylinux2010_x86_64.whl\n","Collecting dataclasses; python_version < \"3.7\"\n","  Using cached https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n","Collecting packaging\n","  Using cached https://files.pythonhosted.org/packages/46/19/c5ab91b1b05cfe63cccd5cfc971db9214c6dd6ced54e33c30d5af1d2bc43/packaging-20.4-py2.py3-none-any.whl\n","Collecting tqdm>=4.27\n","  Using cached https://files.pythonhosted.org/packages/f3/76/4697ce203a3d42b2ead61127b35e5fcc26bba9a35c03b32a2bd342a4c869/tqdm-4.46.1-py2.py3-none-any.whl\n","Collecting sentencepiece\n","  Using cached https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting requests\n","  Using cached https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl\n","Processing /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45/sacremoses-0.0.43-cp36-none-any.whl\n","Collecting tokenizers==0.7.0\n","  Using cached https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting threadpoolctl>=2.0.0\n","  Using cached https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Collecting joblib>=0.11\n","  Using cached https://files.pythonhosted.org/packages/b8/a6/d1a816b89aa1e9e96bcb298eb1ee1854f21662ebc6d55ffa3d7b3b50122b/joblib-0.15.1-py3-none-any.whl\n","Collecting scipy>=0.19.1\n","  Using cached https://files.pythonhosted.org/packages/06/20/d4410683e4d416a11ebc60138f6d925f571ffcfcc3794baf78fff982c98d/scipy-1.5.0-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting setuptools\n","  Using cached https://files.pythonhosted.org/packages/e9/93/4860cebd5ad3ff2664ad3c966490ccb46e3b88458b2095145bca11727ca4/setuptools-47.3.1-py3-none-any.whl\n","Collecting cymem<2.1.0,>=2.0.2\n","  Using cached https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting thinc==7.4.1\n","  Using cached https://files.pythonhosted.org/packages/10/ae/ef3ae5e93639c0ef8e3eb32e3c18341e511b3c515fcfc603f4b808087651/thinc-7.4.1-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting catalogue<1.1.0,>=0.0.7\n","  Using cached https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n","Collecting murmurhash<1.1.0,>=0.28.0\n","  Using cached https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting preshed<3.1.0,>=3.0.2\n","  Using cached https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl\n","Processing /root/.cache/pip/wheels/33/96/74/01741d5dde3d866a4461a05b3fc6aa43bd7ece8729a7264bf7/wasabi-0.7.0-cp36-none-any.whl\n","Collecting blis<0.5.0,>=0.4.0\n","  Using cached https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting srsly<1.1.0,>=1.0.2\n","  Using cached https://files.pythonhosted.org/packages/0e/9a/70bd934dd4d25545c9aa6c8cd4edbac2a33ba9c915439a9209b69f0ec0ad/srsly-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting plac<1.2.0,>=0.9.6\n","  Using cached https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n","Collecting pyparsing>=2.0.2\n","  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n","Collecting six\n","  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n","Collecting certifi>=2017.4.17\n","  Using cached https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl\n","Collecting chardet<4,>=3.0.2\n","  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Using cached https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl\n","Collecting idna<3,>=2.5\n","  Using cached https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl\n","Collecting click\n","  Using cached https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl\n","Collecting importlib-metadata>=0.20; python_version < \"3.8\"\n","  Using cached https://files.pythonhosted.org/packages/98/13/a1d703ec396ade42c1d33df0e1cb691a28b7c08b336a5683912c87e04cd7/importlib_metadata-1.6.1-py2.py3-none-any.whl\n","Collecting zipp>=0.5\n","  Using cached https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.9 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: regex, filelock, numpy, dataclasses, pyparsing, six, packaging, tqdm, sentencepiece, certifi, chardet, urllib3, idna, requests, joblib, click, sacremoses, tokenizers, transformers, threadpoolctl, scipy, scikit-learn, setuptools, cymem, wasabi, srsly, zipp, importlib-metadata, catalogue, murmurhash, preshed, blis, plac, thinc, spacy, bert-extractive-summarizer\n","  Found existing installation: regex 2020.6.8\n","    Uninstalling regex-2020.6.8:\n","      Successfully uninstalled regex-2020.6.8\n","  Found existing installation: filelock 3.0.12\n","    Uninstalling filelock-3.0.12:\n","      Successfully uninstalled filelock-3.0.12\n","  Found existing installation: numpy 1.19.0\n","    Uninstalling numpy-1.19.0:\n","      Successfully uninstalled numpy-1.19.0\n","  Found existing installation: dataclasses 0.7\n","    Uninstalling dataclasses-0.7:\n","      Successfully uninstalled dataclasses-0.7\n","  Found existing installation: pyparsing 2.4.7\n","    Uninstalling pyparsing-2.4.7:\n","      Successfully uninstalled pyparsing-2.4.7\n","  Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Found existing installation: packaging 20.4\n","    Uninstalling packaging-20.4:\n","      Successfully uninstalled packaging-20.4\n","  Found existing installation: tqdm 4.46.1\n","    Uninstalling tqdm-4.46.1:\n","      Successfully uninstalled tqdm-4.46.1\n","  Found existing installation: sentencepiece 0.1.91\n","    Uninstalling sentencepiece-0.1.91:\n","      Successfully uninstalled sentencepiece-0.1.91\n","  Found existing installation: certifi 2020.6.20\n","    Uninstalling certifi-2020.6.20:\n","      Successfully uninstalled certifi-2020.6.20\n","  Found existing installation: chardet 3.0.4\n","    Uninstalling chardet-3.0.4:\n","      Successfully uninstalled chardet-3.0.4\n","  Found existing installation: urllib3 1.25.9\n","    Uninstalling urllib3-1.25.9:\n","      Successfully uninstalled urllib3-1.25.9\n","  Found existing installation: idna 2.9\n","    Uninstalling idna-2.9:\n","      Successfully uninstalled idna-2.9\n","  Found existing installation: requests 2.24.0\n","    Uninstalling requests-2.24.0:\n","      Successfully uninstalled requests-2.24.0\n","  Found existing installation: joblib 0.15.1\n","    Uninstalling joblib-0.15.1:\n","      Successfully uninstalled joblib-0.15.1\n","  Found existing installation: click 7.1.2\n","    Uninstalling click-7.1.2:\n","      Successfully uninstalled click-7.1.2\n","  Found existing installation: sacremoses 0.0.43\n","    Uninstalling sacremoses-0.0.43:\n","      Successfully uninstalled sacremoses-0.0.43\n","  Found existing installation: tokenizers 0.7.0\n","    Uninstalling tokenizers-0.7.0:\n","      Successfully uninstalled tokenizers-0.7.0\n","  Found existing installation: transformers 2.11.0\n","    Uninstalling transformers-2.11.0:\n","      Successfully uninstalled transformers-2.11.0\n","  Found existing installation: threadpoolctl 2.1.0\n","    Uninstalling threadpoolctl-2.1.0:\n","      Successfully uninstalled threadpoolctl-2.1.0\n","  Found existing installation: scipy 1.5.0\n","    Uninstalling scipy-1.5.0:\n","      Successfully uninstalled scipy-1.5.0\n","  Found existing installation: scikit-learn 0.23.1\n","    Uninstalling scikit-learn-0.23.1:\n","      Successfully uninstalled scikit-learn-0.23.1\n","  Found existing installation: setuptools 47.3.1\n","    Uninstalling setuptools-47.3.1:\n","      Successfully uninstalled setuptools-47.3.1\n","  Found existing installation: cymem 2.0.3\n","    Uninstalling cymem-2.0.3:\n","      Successfully uninstalled cymem-2.0.3\n","  Found existing installation: wasabi 0.7.0\n","    Uninstalling wasabi-0.7.0:\n","      Successfully uninstalled wasabi-0.7.0\n","  Found existing installation: srsly 1.0.2\n","    Uninstalling srsly-1.0.2:\n","      Successfully uninstalled srsly-1.0.2\n","  Found existing installation: zipp 3.1.0\n","    Uninstalling zipp-3.1.0:\n","      Successfully uninstalled zipp-3.1.0\n","  Found existing installation: importlib-metadata 1.6.1\n","    Uninstalling importlib-metadata-1.6.1:\n","      Successfully uninstalled importlib-metadata-1.6.1\n","  Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Found existing installation: murmurhash 1.0.2\n","    Uninstalling murmurhash-1.0.2:\n","      Successfully uninstalled murmurhash-1.0.2\n","  Found existing installation: preshed 3.0.2\n","    Uninstalling preshed-3.0.2:\n","      Successfully uninstalled preshed-3.0.2\n","  Found existing installation: blis 0.4.1\n","    Uninstalling blis-0.4.1:\n","      Successfully uninstalled blis-0.4.1\n","  Found existing installation: plac 1.1.3\n","    Uninstalling plac-1.1.3:\n","      Successfully uninstalled plac-1.1.3\n","  Found existing installation: thinc 7.4.1\n","    Uninstalling thinc-7.4.1:\n","      Successfully uninstalled thinc-7.4.1\n","  Found existing installation: spacy 2.3.0\n","    Uninstalling spacy-2.3.0:\n","      Successfully uninstalled spacy-2.3.0\n","  Found existing installation: bert-extractive-summarizer 0.4.2\n","    Uninstalling bert-extractive-summarizer-0.4.2:\n","      Successfully uninstalled bert-extractive-summarizer-0.4.2\n","Successfully installed bert-extractive-summarizer-0.4.2 blis-0.4.1 catalogue-1.0.0 certifi-2020.6.20 chardet-3.0.4 click-7.1.2 cymem-2.0.3 dataclasses-0.7 filelock-3.0.12 idna-2.9 importlib-metadata-1.6.1 joblib-0.15.1 murmurhash-1.0.2 numpy-1.19.0 packaging-20.4 plac-1.1.3 preshed-3.0.2 pyparsing-2.4.7 regex-2020.6.8 requests-2.24.0 sacremoses-0.0.43 scikit-learn-0.23.1 scipy-1.5.0 sentencepiece-0.1.91 setuptools-47.3.1 six-1.15.0 spacy-2.3.0 srsly-1.0.2 thinc-7.4.1 threadpoolctl-2.1.0 tokenizers-0.7.0 tqdm-4.46.1 transformers-2.11.0 urllib3-1.25.9 wasabi-0.7.0 zipp-3.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","chardet","idna","numpy","pkg_resources","pyparsing","requests","six","tqdm","urllib3"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"m_7fLY3R-ao-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":625},"executionInfo":{"status":"ok","timestamp":1593108131006,"user_tz":-330,"elapsed":45377,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"32c80cc9-b72f-484f-9c3f-738029e98461"},"source":["!sudo python -m nltk.downloader stopwords\n","!sudo python -m nltk.downloader universal_tagset\n","!sudo python -m spacy download en # download the english model"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Package universal_tagset is already up-to-date!\n","Requirement already satisfied: en_core_web_sm==2.3.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.0/en_core_web_sm-2.3.0.tar.gz#egg=en_core_web_sm==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.3.0) (2.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (4.46.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.0.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (47.3.1)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (0.4.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (0.7.0)\n","Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (7.4.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.2)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.19.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.24.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.1.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.6.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.25.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2020.6.20)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.1.0)\n","\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2mâœ” Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e_SGzrquAmwd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593108131604,"user_tz":-330,"elapsed":630,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"799ecad1-3a3e-4eb7-ec5f-03b485ef9774"},"source":["import nltk \n","\n","\n","paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds. From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours. Yet, we have not done this to any other nation. We have not conquered anyone. We have not grabbed their land, their culture, their history and tried to enforce our way of life on them. Why? Because we respect the freedom of others.\n","\n","That is why my first vision is that of FREEDOM.\n","\n","I believe that India got its first vision of this in 1857, when we started the war of Independence. It is this freedom that we must protect and nurture and build on. If we are not free, no one will respect us.\n","\n","My second vision for Indiaâ€™s DEVELOPMENT.\n","\n","For fifty years we have been a developing nation. It is time we see ourselves as a developed nation. We are among top five nations of the world in terms of GDP. We have 10 per cent growth rate in most areas. Our poverty levels are falling. Our achievements are being globally recognised today. Yet we lack the self-confidence to see ourselves as a developed nation, self-reliant and self-assured. Isnâ€™t this incorrect?\n","\n","I have a THIRD vision.\n","\n","India must stand up to the world. Because I believe that, unless India stands up to the world, no one will respect us. Only strength respects strength. We must be strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n","\n","My good fortune was to have worked with three great minds. Dr Vikram Sarabhai of the Department of Space, Professor Satish Dhawan, who succeeded him and Dr Brahm Prakash, the father of nuclear material. I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.\n","\n","I see four milestones in my career: \"\"\"\n","\n","#Cleaning the text\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","\n","ps = PorterStemmer()\n","wordnet=WordNetLemmatizer()\n","\n","#Tokenizing sentences\n","sentences = nltk.sent_tokenize(paragraph)\n","\n","print(sentences)\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["['I have three visions for India.', 'In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds.', 'From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours.', 'Yet, we have not done this to any other nation.', 'We have not conquered anyone.', 'We have not grabbed their land, their culture, their history and tried to enforce our way of life on them.', 'Why?', 'Because we respect the freedom of others.', 'That is why my first vision is that of FREEDOM.', 'I believe that India got its first vision of this in 1857, when we started the war of Independence.', 'It is this freedom that we must protect and nurture and build on.', 'If we are not free, no one will respect us.', 'My second vision for Indiaâ€™s DEVELOPMENT.', 'For fifty years we have been a developing nation.', 'It is time we see ourselves as a developed nation.', 'We are among top five nations of the world in terms of GDP.', 'We have 10 per cent growth rate in most areas.', 'Our poverty levels are falling.', 'Our achievements are being globally recognised today.', 'Yet we lack the self-confidence to see ourselves as a developed nation, self-reliant and self-assured.', 'Isnâ€™t this incorrect?', 'I have a THIRD vision.', 'India must stand up to the world.', 'Because I believe that, unless India stands up to the world, no one will respect us.', 'Only strength respects strength.', 'We must be strong not only as a military power but also as an economic power.', 'Both must go hand-in-hand.', 'My good fortune was to have worked with three great minds.', 'Dr Vikram Sarabhai of the Department of Space, Professor Satish Dhawan, who succeeded him and Dr Brahm Prakash, the father of nuclear material.', 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.', 'I see four milestones in my career:']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-3LT8bz1XHOo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593108251094,"user_tz":-330,"elapsed":15700,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"14dcc1cd-c0d5-49b0-de05-c48426375726"},"source":["from summarizer import Summarizer\n","model = Summarizer()\n","result = model(paragraph, min_length=60, max_length = 500 , ratio = 0.4)\n","summarized_text = ''.join(result)\n","print (summarized_text)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds. We have not grabbed their land, their culture, their history and tried to enforce our way of life on them. We must be strong not only as a military power but also as an economic power. Dr Vikram Sarabhai of the Department of Space, Professor Satish Dhawan, who succeeded him and Dr Brahm Prakash, the father of nuclear material.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nukiH99bDRHl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":538},"executionInfo":{"status":"ok","timestamp":1593108174737,"user_tz":-330,"elapsed":1883,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"88198bf0-fb1d-4e17-d9ef-d27b8638eb83"},"source":["#After cleaning the text everything is stored in corpus\n","corpus = []\n","\n","for i in range(len(sentences)):\n","    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n","    review = review.lower()\n","    review = review.split()\n","    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n","    review = ' '.join(review)\n","    corpus.append(review)\n","    print(review)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["three vision india\n","year history people world come invaded u captured land conquered mind\n","alexander onwards greek turk mogul portuguese british french dutch came looted u took\n","yet done nation\n","conquered anyone\n","grabbed land culture history tried enforce way life\n","\n","respect freedom others\n","first vision freedom\n","believe india got first vision started war independence\n","freedom must protect nurture build\n","free one respect u\n","second vision india development\n","fifty year developing nation\n","time see developed nation\n","among top five nation world term gdp\n","per cent growth rate area\n","poverty level falling\n","achievement globally recognised today\n","yet lack self confidence see developed nation self reliant self assured\n","incorrect\n","third vision\n","india must stand world\n","believe unless india stand world one respect u\n","strength respect strength\n","must strong military power also economic power\n","must go hand hand\n","good fortune worked three great mind\n","dr vikram sarabhai department space professor satish dhawan succeeded dr brahm prakash father nuclear material\n","lucky worked three closely consider great opportunity life\n","see four milestone career\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kM7vXDQPBiHm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593108174739,"user_tz":-330,"elapsed":36,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"ef60d04a-da27-43c2-ca39-022f26aecc4a"},"source":["#Preparing the dataset \n","sent = nltk.sent_tokenize(review)\n","sent = [nltk.word_tokenize(sentence) for sentence in sentences]  \n","print(sent)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[['I', 'have', 'three', 'visions', 'for', 'India', '.'], ['In', '3000', 'years', 'of', 'our', 'history', ',', 'people', 'from', 'all', 'over', 'the', 'world', 'have', 'come', 'and', 'invaded', 'us', ',', 'captured', 'our', 'lands', ',', 'conquered', 'our', 'minds', '.'], ['From', 'Alexander', 'onwards', ',', 'the', 'Greeks', ',', 'the', 'Turks', ',', 'the', 'Moguls', ',', 'the', 'Portuguese', ',', 'the', 'British', ',', 'the', 'French', ',', 'the', 'Dutch', ',', 'all', 'of', 'them', 'came', 'and', 'looted', 'us', ',', 'took', 'over', 'what', 'was', 'ours', '.'], ['Yet', ',', 'we', 'have', 'not', 'done', 'this', 'to', 'any', 'other', 'nation', '.'], ['We', 'have', 'not', 'conquered', 'anyone', '.'], ['We', 'have', 'not', 'grabbed', 'their', 'land', ',', 'their', 'culture', ',', 'their', 'history', 'and', 'tried', 'to', 'enforce', 'our', 'way', 'of', 'life', 'on', 'them', '.'], ['Why', '?'], ['Because', 'we', 'respect', 'the', 'freedom', 'of', 'others', '.'], ['That', 'is', 'why', 'my', 'first', 'vision', 'is', 'that', 'of', 'FREEDOM', '.'], ['I', 'believe', 'that', 'India', 'got', 'its', 'first', 'vision', 'of', 'this', 'in', '1857', ',', 'when', 'we', 'started', 'the', 'war', 'of', 'Independence', '.'], ['It', 'is', 'this', 'freedom', 'that', 'we', 'must', 'protect', 'and', 'nurture', 'and', 'build', 'on', '.'], ['If', 'we', 'are', 'not', 'free', ',', 'no', 'one', 'will', 'respect', 'us', '.'], ['My', 'second', 'vision', 'for', 'India', 'â€™', 's', 'DEVELOPMENT', '.'], ['For', 'fifty', 'years', 'we', 'have', 'been', 'a', 'developing', 'nation', '.'], ['It', 'is', 'time', 'we', 'see', 'ourselves', 'as', 'a', 'developed', 'nation', '.'], ['We', 'are', 'among', 'top', 'five', 'nations', 'of', 'the', 'world', 'in', 'terms', 'of', 'GDP', '.'], ['We', 'have', '10', 'per', 'cent', 'growth', 'rate', 'in', 'most', 'areas', '.'], ['Our', 'poverty', 'levels', 'are', 'falling', '.'], ['Our', 'achievements', 'are', 'being', 'globally', 'recognised', 'today', '.'], ['Yet', 'we', 'lack', 'the', 'self-confidence', 'to', 'see', 'ourselves', 'as', 'a', 'developed', 'nation', ',', 'self-reliant', 'and', 'self-assured', '.'], ['Isn', 'â€™', 't', 'this', 'incorrect', '?'], ['I', 'have', 'a', 'THIRD', 'vision', '.'], ['India', 'must', 'stand', 'up', 'to', 'the', 'world', '.'], ['Because', 'I', 'believe', 'that', ',', 'unless', 'India', 'stands', 'up', 'to', 'the', 'world', ',', 'no', 'one', 'will', 'respect', 'us', '.'], ['Only', 'strength', 'respects', 'strength', '.'], ['We', 'must', 'be', 'strong', 'not', 'only', 'as', 'a', 'military', 'power', 'but', 'also', 'as', 'an', 'economic', 'power', '.'], ['Both', 'must', 'go', 'hand-in-hand', '.'], ['My', 'good', 'fortune', 'was', 'to', 'have', 'worked', 'with', 'three', 'great', 'minds', '.'], ['Dr', 'Vikram', 'Sarabhai', 'of', 'the', 'Department', 'of', 'Space', ',', 'Professor', 'Satish', 'Dhawan', ',', 'who', 'succeeded', 'him', 'and', 'Dr', 'Brahm', 'Prakash', ',', 'the', 'father', 'of', 'nuclear', 'material', '.'], ['I', 'was', 'lucky', 'to', 'have', 'worked', 'with', 'all', 'three', 'of', 'them', 'closely', 'and', 'consider', 'this', 'the', 'great', 'opportunity', 'of', 'my', 'life', '.'], ['I', 'see', 'four', 'milestones', 'in', 'my', 'career', ':']]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vNbe8IU-D6La","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1593108174740,"user_tz":-330,"elapsed":28,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"c5ef7c7b-64a1-4edf-b524-d58d244855eb"},"source":["#To find frequency of words in corpus\n"," \n","wordfreq = {}\n","for sentence in corpus:\n","    tokens = nltk.word_tokenize(sentence)\n","    for token in tokens:\n","        if token not in wordfreq.keys():\n","            wordfreq[token] = 1\n","        else:\n","            wordfreq[token] += 1\n","            \n","#In the most frequency list we get the frequency of words in descending order\n","import heapq\n","most_freq = heapq.nlargest(200, wordfreq, key=wordfreq.get)\n","print(most_freq)\n","\n","sentence_vectors = []\n","for sentence in corpus:\n","    sentence_tokens = nltk.word_tokenize(sentence)\n","    sent_vec = []\n","    for token in most_freq:\n","        if token in sentence_tokens:\n","            sent_vec.append(1)\n","        else:\n","            sent_vec.append(0)\n","    sentence_vectors.append(sent_vec)\n","print(sentence_tokens)\n","print(sentence_vectors)\n","print(sent_vec)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["['vision', 'india', 'nation', 'world', 'u', 'respect', 'must', 'three', 'freedom', 'see', 'self', 'year', 'history', 'land', 'conquered', 'mind', 'yet', 'life', 'first', 'believe', 'one', 'developed', 'stand', 'strength', 'power', 'hand', 'worked', 'great', 'dr', 'people', 'come', 'invaded', 'captured', 'alexander', 'onwards', 'greek', 'turk', 'mogul', 'portuguese', 'british', 'french', 'dutch', 'came', 'looted', 'took', 'done', 'anyone', 'grabbed', 'culture', 'tried', 'enforce', 'way', 'others', 'got', 'started', 'war', 'independence', 'protect', 'nurture', 'build', 'free', 'second', 'development', 'fifty', 'developing', 'time', 'among', 'top', 'five', 'term', 'gdp', 'per', 'cent', 'growth', 'rate', 'area', 'poverty', 'level', 'falling', 'achievement', 'globally', 'recognised', 'today', 'lack', 'confidence', 'reliant', 'assured', 'incorrect', 'third', 'unless', 'strong', 'military', 'also', 'economic', 'go', 'good', 'fortune', 'vikram', 'sarabhai', 'department', 'space', 'professor', 'satish', 'dhawan', 'succeeded', 'brahm', 'prakash', 'father', 'nuclear', 'material', 'lucky', 'closely', 'consider', 'opportunity', 'four', 'milestone', 'career']\n","['see', 'four', 'milestone', 'career']\n","[[1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZGNZXmX2EadT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593108174741,"user_tz":-330,"elapsed":21,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"6f032d82-8e5e-45bd-e9fe-fad9c27f593f"},"source":["#Parts of Speech\n","nltk.pos_tag(most_freq)\n","# print(text_tok)\n","pos_tagged = nltk.pos_tag(most_freq)\n"," # print the list of tuples: (word,word_class)\n","print(pos_tagged)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[('vision', 'NN'), ('india', 'NN'), ('nation', 'NN'), ('world', 'NN'), ('u', 'JJ'), ('respect', 'NN'), ('must', 'MD'), ('three', 'CD'), ('freedom', 'NN'), ('see', 'VB'), ('self', 'JJ'), ('year', 'NN'), ('history', 'NN'), ('land', 'NN'), ('conquered', 'VBD'), ('mind', 'NN'), ('yet', 'RB'), ('life', 'NN'), ('first', 'RB'), ('believe', 'VB'), ('one', 'CD'), ('developed', 'VBN'), ('stand', 'VB'), ('strength', 'NN'), ('power', 'NN'), ('hand', 'NN'), ('worked', 'VBD'), ('great', 'JJ'), ('dr', 'JJ'), ('people', 'NNS'), ('come', 'VBP'), ('invaded', 'VBN'), ('captured', 'JJ'), ('alexander', 'NN'), ('onwards', 'NNS'), ('greek', 'JJ'), ('turk', 'NN'), ('mogul', 'NN'), ('portuguese', 'JJ'), ('british', 'JJ'), ('french', 'JJ'), ('dutch', 'NN'), ('came', 'VBD'), ('looted', 'JJ'), ('took', 'VBD'), ('done', 'VBN'), ('anyone', 'NN'), ('grabbed', 'JJ'), ('culture', 'NN'), ('tried', 'VBD'), ('enforce', 'JJ'), ('way', 'NN'), ('others', 'NNS'), ('got', 'VBD'), ('started', 'JJ'), ('war', 'NN'), ('independence', 'NN'), ('protect', 'JJ'), ('nurture', 'NN'), ('build', 'VBP'), ('free', 'JJ'), ('second', 'NN'), ('development', 'NN'), ('fifty', 'JJ'), ('developing', 'VBG'), ('time', 'NN'), ('among', 'IN'), ('top', 'JJ'), ('five', 'CD'), ('term', 'NN'), ('gdp', 'NN'), ('per', 'IN'), ('cent', 'NN'), ('growth', 'NN'), ('rate', 'NN'), ('area', 'NN'), ('poverty', 'NN'), ('level', 'NN'), ('falling', 'VBG'), ('achievement', 'JJ'), ('globally', 'RB'), ('recognised', 'VBN'), ('today', 'NN'), ('lack', 'NN'), ('confidence', 'NN'), ('reliant', 'NN'), ('assured', 'VBD'), ('incorrect', 'JJ'), ('third', 'JJ'), ('unless', 'IN'), ('strong', 'JJ'), ('military', 'NN'), ('also', 'RB'), ('economic', 'JJ'), ('go', 'VB'), ('good', 'JJ'), ('fortune', 'NN'), ('vikram', 'NNS'), ('sarabhai', 'VBP'), ('department', 'NN'), ('space', 'NN'), ('professor', 'NN'), ('satish', 'JJ'), ('dhawan', 'NN'), ('succeeded', 'VBD'), ('brahm', 'NN'), ('prakash', 'NN'), ('father', 'NN'), ('nuclear', 'JJ'), ('material', 'NN'), ('lucky', 'RBR'), ('closely', 'RB'), ('consider', 'VB'), ('opportunity', 'NN'), ('four', 'CD'), ('milestone', 'NN'), ('career', 'NN')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hHps3lpbnylT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593108205470,"user_tz":-330,"elapsed":30742,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"4f03c70a-5672-4c53-ea52-102de237e391"},"source":["!python -m spacy download en\n","!pip install pke"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.3.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.0/en_core_web_sm-2.3.0.tar.gz#egg=en_core_web_sm==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.3.0) (2.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (4.46.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.19.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (0.7.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.1.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (47.3.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.0.3)\n","Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (7.4.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.24.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.6.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.25.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2020.6.20)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.1.0)\n","\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2mâœ” Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","Requirement already satisfied: pke in /usr/local/lib/python3.6/dist-packages (1.8.1)\n","Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from pke) (1.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pke) (1.19.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pke) (2.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pke) (3.5)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from pke) (0.0)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pke) (2.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pke) (0.15.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pke) (1.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pke) (1.15.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pke) (0.16.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pke) (4.4.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk->pke) (4.46.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk->pke) (7.1.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk->pke) (2020.6.8)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->pke) (0.23.1)\n","Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (7.4.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (1.1.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (0.4.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (47.3.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (3.0.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (0.7.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (1.0.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (1.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (2.0.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke) (2.24.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->pke) (2.1.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pke) (1.6.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke) (1.25.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke) (2.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pke) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6mJaEiiDEUOX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1593108870923,"user_tz":-330,"elapsed":1842,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"0789b109-0fb0-4de1-ff87-ba47a93dc90c"},"source":["#KEYWORD EXTRACTION\n","import pprint\n","import itertools\n","import re\n","import pke\n","import string\n","from nltk.corpus import stopwords\n","\n","def get_nouns_multipartite(text):\n","    out=[]\n","\n","    extractor = pke.unsupervised.MultipartiteRank()\n","    extractor.load_document(input=text)\n","    #    not contain punctuation marks or stopwords as candidates.\n","    pos = {'PROPN'}\n","    #pos = {'VERB', 'ADJ', 'NOUN'}\n","    stoplist = list(string.punctuation)\n","    stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n","    stoplist += stopwords.words('english')\n","    extractor.candidate_selection(pos=pos, stoplist=stoplist)\n","    # 4. build the Multipartite graph and rank candidates using random walk,\n","    #    alpha controls the weight adjustment mechanism, see TopicRank for\n","    #    threshold/method parameters.\n","    extractor.candidate_weighting(alpha=1.1,\n","                                  threshold=0.75,\n","                                  method='average')\n","    keyphrases = extractor.get_n_best(n=17)\n","\n","    for key in keyphrases:\n","        out.append(key[0])\n","\n","    return out\n","\n","keywords = get_nouns_multipartite(paragraph) \n","print (keywords)\n","filtered_keys=[]\n","for keyword in keywords:\n","    if keyword.lower() in summarized_text.lower():\n","        filtered_keys.append(keyword)\n","        \n","print (filtered_keys)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["['india', 'space', 'department', 'moguls', 'turks', 'professor satish dhawan', 'greeks', 'portuguese', 'french', 'dr vikram sarabhai', 'dutch', 'alexander', 'development', 'dr brahm prakash', 'third', 'freedom', 'independence']\n","['space', 'department', 'professor satish dhawan', 'dr vikram sarabhai', 'dr brahm prakash']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NE5Myp-QHTBY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1593108876142,"user_tz":-330,"elapsed":1268,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"9d491722-df09-42e8-8b06-1c558cd13ed5"},"source":["#Using word2vec to preserve the semantic information and relation between two different words.\n","from gensim.models import Word2Vec\n","#Training the Word2Vec model\n","model = Word2Vec(sent,min_count=1)\n","words = model.wv.vocab\n","\n","#Finding Word Vector\n","vector = model.wv['freedom']\n","\n","#Most similar words\n","similar = model.wv.most_similar('freedom')\n","print(similar)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"],"name":"stderr"},{"output_type":"stream","text":["[('not', 0.279818594455719), ('my', 0.24343639612197876), ('history', 0.23138155043125153), ('among', 0.22126704454421997), ('why', 0.19363167881965637), ('grabbed', 0.17608577013015747), ('Because', 0.17363104224205017), ('and', 0.1719323694705963), ('Prakash', 0.17130789160728455), ('That', 0.1671636700630188)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TBUu9EXPH_qx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593108887219,"user_tz":-330,"elapsed":1743,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}}},"source":["\n","#Using pytextrank\n","import spacy\n","import pytextrank\n","\n","# load a spaCy model, depending on language, scale, etc.\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# add PyTextRank to the spaCy pipeline\n","tr = pytextrank.TextRank()\n","nlp.add_pipe(tr.PipelineComponent, name=\"textrank\", last=True)\n","doc = nlp(paragraph)\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"-sUdjAWMI3sV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593108888942,"user_tz":-330,"elapsed":1935,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"1e0919a7-03a3-4794-e69f-b603f66abb26"},"source":["#SENTENCE MAPPING\n","#For each keywords we are mapping the sentences which contain those keywords from the summarized text\n","from nltk.tokenize import sent_tokenize\n","\n","def tokenize_sentences(text):\n","    sentences = [sent_tokenize(text)]\n","    sentences = [y for x in sentences for y in x]\n","    return sentences\n","\n","from flashtext import KeywordProcessor\n","def get_sentences_for_keyword(keywords, sentences):\n","    keyword_processor = KeywordProcessor()\n","    keyword_sentences = {}\n","    for word in keywords:\n","        keyword_sentences[word] = []\n","        keyword_processor.add_keyword(word)\n","    for sentence in sentences:\n","        keywords_found = keyword_processor.extract_keywords(sentence)\n","        for key in keywords_found:\n","            keyword_sentences[key].append(sentence)\n","\n","    for key in keyword_sentences.keys():\n","        values = keyword_sentences[key]\n","        values = sorted(values, key=len, reverse=True)\n","        keyword_sentences[key] = values\n","    return keyword_sentences\n","\n","sentences = tokenize_sentences(summarized_text)\n","keyword_sentence_mapping = get_sentences_for_keyword(filtered_keys, sentences)\n","\n","print (keyword_sentence_mapping)       \n","\n","\n","\n","    "],"execution_count":17,"outputs":[{"output_type":"stream","text":["{'space': ['Dr Vikram Sarabhai of the Department of Space, Professor Satish Dhawan, who succeeded him and Dr Brahm Prakash, the father of nuclear material.'], 'department': ['Dr Vikram Sarabhai of the Department of Space, Professor Satish Dhawan, who succeeded him and Dr Brahm Prakash, the father of nuclear material.'], 'professor satish dhawan': ['Dr Vikram Sarabhai of the Department of Space, Professor Satish Dhawan, who succeeded him and Dr Brahm Prakash, the father of nuclear material.'], 'dr vikram sarabhai': ['Dr Vikram Sarabhai of the Department of Space, Professor Satish Dhawan, who succeeded him and Dr Brahm Prakash, the father of nuclear material.'], 'dr brahm prakash': ['Dr Vikram Sarabhai of the Department of Space, Professor Satish Dhawan, who succeeded him and Dr Brahm Prakash, the father of nuclear material.']}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cqHJTvPJR2cK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":322},"executionInfo":{"status":"ok","timestamp":1593108969842,"user_tz":-330,"elapsed":1946,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}},"outputId":"e069479f-e010-4271-8a17-fac0ca60f45a"},"source":["#MCQ Generation\n","import requests\n","import json\n","import re\n","import random\n","from pywsd.similarity import max_similarity\n","from pywsd.lesk import adapted_lesk\n","from pywsd.lesk import simple_lesk\n","from pywsd.lesk import cosine_lesk\n","\n","\n","# Distractors from Word2Vec\n","def get_distractors_word2vec(syn,word):\n","    distractors=[]\n","    word= word.lower()\n","    orig_word = word\n","    if len(word.split())>0:\n","        word = word.replace(\" \",\"_\")\n","    hypernym = syn.hypernyms()\n","    if len(hypernym) == 0: \n","        return distractors\n","    for item in hypernym[0].hyponyms():\n","        name = item.lemmas()[0].name()\n","        #print (\"name \",name, \" word\",orig_word)\n","        if name == orig_word:\n","            continue\n","        name = name.replace(\"_\",\" \")\n","        name = \" \".join(w.capitalize() for w in name.split())\n","        if name is not None and name not in distractors:\n","            distractors.append(name)\n","    return distractors\n","\n","def get_wordsense(sent,word):\n","    word= word.lower()\n","    \n","    if len(word.split())>0:\n","        word = word.replace(\" \",\"_\")\n","    \n","    \n","    synsets = wn.synsets(word,'n')\n","    if synsets:\n","        wup = max_similarity(sent, word, 'wup', pos='n')\n","        adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n","        lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n","        return synsets[lowest_index]\n","    else:\n","        return None\n","\n","# Distractors from http://conceptnet.io/\n","def get_distractors_conceptnet(word):\n","    word = word.lower()\n","    original_word= word\n","    if (len(word.split())>0):\n","        word = word.replace(\" \",\"_\")\n","    distractor_list = [] \n","    url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n","    obj = requests.get(url).json()\n","\n","    for edge in obj['edges']:\n","        link = edge['end']['term'] \n","\n","        url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n","        obj2 = requests.get(url2).json()\n","        for edge in obj2['edges']:\n","            word2 = edge['start']['label']\n","            if word2 not in distractor_list and original_word.lower() not in word2.lower():\n","                distractor_list.append(word2)\n","                   \n","    return distractor_list\n","\n","key_distractor_list = {}\n","\n","for keyword in keyword_sentence_mapping:\n","    wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n","    if wordsense:\n","        distractors = get_distractors_word2vec(wordsense,keyword)\n","        if len(distractors) ==0:\n","            distractors = get_distractors_conceptnet(keyword)\n","        if len(distractors) != 0:\n","            key_distractor_list[keyword] = distractors\n","    else:\n","        \n","        distractors = get_distractors_conceptnet(keyword)\n","        if len(distractors) != 0:\n","            key_distractor_list[keyword] = distractors\n","\n","index = 1\n","\n","for each in key_distractor_list:\n","    sentence = keyword_sentence_mapping[each][0]\n","    pattern = re.compile(each, re.IGNORECASE)\n","    output = pattern.sub( \" _______ \", sentence)\n","    print (\"%s)\"%(index),output)\n","    choices = [each.capitalize()] + key_distractor_list[each]\n","    top4choices = choices[:4]\n","    random.shuffle(top4choices)\n","    optionchoices = ['a','b','c','d']\n","    for idx,choice in enumerate(top4choices):\n","        print (\"\\t\",optionchoices[idx],\")\",\" \",choice)\n","    print (\"\\nMore options: \", choices[4:20],\"\\n\\n\")\n","    index = index + 1\n","    \n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["1) Dr Vikram Sarabhai of the Department of  _______ , Professor Satish Dhawan, who succeeded him and Dr Brahm Prakash, the father of nuclear material.\n","\t a )   Shapelessness\n","\t b )   Space\n","\t c )   Blob\n","\n","More options:  [] \n","\n","\n","2) Dr Vikram Sarabhai of the  _______  of Space, Professor Satish Dhawan, who succeeded him and Dr Brahm Prakash, the father of nuclear material.\n","\t a )   Canton\n","\t b )   City\n","\t c )   Department\n","\t d )   Borough\n","\n","More options:  ['Commune', 'Country', 'County', 'County Palatine', 'Federal District', 'Municipality', 'Prefecture', 'Reservation', 'School District', 'Shire', 'State', 'Township', 'Ward'] \n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8QWeZSLjvwDO","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593108206658,"user_tz":-330,"elapsed":50,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}}},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMhbh_MGwZpn","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593108206659,"user_tz":-330,"elapsed":40,"user":{"displayName":"Aiswarya Lenin","photoUrl":"","userId":"00001954145958883752"}}},"source":[""],"execution_count":null,"outputs":[]}]}